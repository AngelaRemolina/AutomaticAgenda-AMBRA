{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has the model creation for first time running with original data. The retraining on real time with ongoing data is on file `main.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import json\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activities = []\n",
    "with open(\"data_activities.json\", \"r\") as f:\n",
    "    data_activities = json.load(f)\n",
    "\n",
    "data_feedback = []\n",
    "with open(\"data_feedback.json\", \"r\") as f:\n",
    "    data_feedback = json.load(f)\n",
    "\n",
    "unique_activity_ids = set(activity[\"act_id\"] for activity in data_activities)\n",
    "unique_user_ids = set(u[\"user_id\"] for u in data_feedback)\n",
    "\n",
    "# convert to bytes (tensorflow requires)\n",
    "unique_user_ids = np.array(list(map(str.encode, unique_user_ids)))\n",
    "unique_activity_ids = np.array(list(map(str.encode, unique_activity_ids)))\n",
    "\n",
    "# cast activity data into TF tensor\n",
    "activities_list = [act[\"act_id\"] for act in data_activities]\n",
    "activities = tf.data.Dataset.from_tensor_slices(activities_list)\n",
    "\n",
    "# cast feedback data into TF tensor\n",
    "user_id_list = []\n",
    "act_id_list = []\n",
    "act_class_list = []\n",
    "for entry in data_feedback:\n",
    "    user_id_list.append(entry[\"user_id\"])\n",
    "    act_id_list.append(entry[\"act_id\"])\n",
    "    # from 'act_id' extract also the activity class\n",
    "    act_class_list.append(\n",
    "        next(filter(lambda x: x[\"act_id\"] == entry[\"act_id\"], data_activities), {}).get(\n",
    "            \"act_class\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "feedback = tf.data.Dataset.from_tensor_slices(\n",
    "    {\n",
    "        \"user_id\": user_id_list,\n",
    "        \"act_id\": act_id_list,\n",
    "        \"act_class\": act_class_list,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSION = 32  # Higher values will correspond to models that may be more accurate, but will also be slower to fit and more prone to overfitting.\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCH = 3\n",
    "NUM_SAMPLES = len(data_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------Train/test split ---------------\n",
    "shuffled = feedback.shuffle(buffer_size=NUM_SAMPLES, reshuffle_each_iteration=False)\n",
    "\n",
    "train_percent = 0.8  # 0.2 test\n",
    "\n",
    "train_size = int(train_percent * NUM_SAMPLES)\n",
    "test_size = NUM_SAMPLES - train_size\n",
    "\n",
    "train = shuffled.take(train_size)\n",
    "test = shuffled.skip(train_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique activities: 11\n",
      "Unique users: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique activities: {}\".format(len(unique_activity_ids)))\n",
    "print(\"Unique users: {}\".format(len(unique_user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivityModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, retrieval_weight: float) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.activity_model: tf.keras.layers.Layer = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=unique_activity_ids, mask_token=None\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    len(unique_activity_ids) + 1, EMBEDDING_DIMENSION\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=unique_user_ids, mask_token=None\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    len(unique_user_ids) + 1, EMBEDDING_DIMENSION\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=activities.batch(128).map(self.activity_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the activity features and pass them into the activity model.\n",
    "        activity_embeddings = self.activity_model(features[\"act_id\"])\n",
    "\n",
    "        return (user_embeddings, activity_embeddings)\n",
    "\n",
    "    def compute_loss(\n",
    "        self, features: Dict[Text, tf.Tensor], training=False\n",
    "    ) -> tf.Tensor:\n",
    "\n",
    "        user_embeddings, activity_embeddings = self(features)\n",
    "\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, activity_embeddings)\n",
    "\n",
    "        return self.retrieval_weight * retrieval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x00000224AF7C7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x00000224AF7C7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5000 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 10.7402 - regularization_loss: 0.0000e+00 - total_loss: 10.7402\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 110ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.8333 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 10.6778 - regularization_loss: 0.0000e+00 - total_loss: 10.6778\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 120ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.8333 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 10.5858 - regularization_loss: 0.0000e+00 - total_loss: 10.5858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x224b09fba10>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ActivityModel(retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "cached_train = train.shuffle(NUM_SAMPLES).batch(BATCH_SIZE).cache()\n",
    "cached_test = test.batch(BATCH_SIZE).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x00000224A8079940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x00000224A8079940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 823ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 1.4761 - regularization_loss: 0.0000e+00 - total_loss: 1.4761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 1.0,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 1.0,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 1.0,\n",
       " 'loss': 1.476138710975647,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.476138710975647}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"activity_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_11 (Sequential)  (None, 32)                384       \n",
      "                                                                 \n",
      " sequential_12 (Sequential)  (None, 32)                128       \n",
      "                                                                 \n",
      " retrieval_7 (Retrieval)     multiple                  1         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 513 (2.00 KB)\n",
      "Trainable params: 512 (2.00 KB)\n",
      "Non-trainable params: 1 (4.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(user, top_n=3):\n",
    "\n",
    "    # Create a model that takes in raw query features, and\n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "    # recommends activities out of the entire activity dataset.\n",
    "    index.index_from_dataset(\n",
    "        tf.data.Dataset.zip(\n",
    "            (\n",
    "                activities.batch(BATCH_SIZE),\n",
    "                activities.batch(BATCH_SIZE).map(model.activity_model),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Get recommendations.\n",
    "    _, titles = index(tf.constant([str(user)]))\n",
    "\n",
    "    print(\"Top {} recommendations for user {}:\\n\".format(top_n, user))\n",
    "    for i, title in enumerate(titles[0, :top_n].numpy()):\n",
    "        print(\"{}. {}\".format(i + 1, title.decode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user U3:\n",
      "\n",
      "1. A5\n",
      "2. A2\n",
      "3. A7\n",
      "4. A4\n",
      "5. A8\n"
     ]
    }
   ],
   "source": [
    "predicting(\"U3\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x00000224B1A82A50>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x00000224B1A82A50>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./trained_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./trained_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/70358350/how-to-deal-with-tf-saved-model-savemodel-filepath-error\n",
    "model.retrieval_task = tfrs.tasks.Retrieval()  # Removes the metrics.\n",
    "model.compile()\n",
    "model.save(\"./trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.saving.legacy.saved_model.load.ActivityModel at 0x224af833c90>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"./trained_model\")\n",
    "loaded_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
